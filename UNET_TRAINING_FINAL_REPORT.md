# U-Net í›ˆë ¨ ì™„ë£Œ ë³´ê³ ì„œ

**í›ˆë ¨ ì™„ë£Œ ì¼ì‹œ**: 2026-01-11
**í›ˆë ¨ ëª¨ë¸**: U-Net (Vocal Tract Segmentation)
**ë°ì´í„°ì…‹**: Pseudo Labels (200 ìƒ˜í”Œ)

---

## ğŸ“Š ìµœì¢… ì„±ëŠ¥ ê²°ê³¼

### Validation ì„±ëŠ¥ (ìµœê³ )
- **Epoch**: 95
- **Validation Dice Score**: **0.9219** (92.19%)
- **Validation Loss**: 0.128

### Test ì„±ëŠ¥ (ìµœì¢… í‰ê°€)
- **Test Dice Score**: **0.9142** (91.42%)
- **Test Loss**: 0.1350

### Training ì„±ëŠ¥ (ë§ˆì§€ë§‰ epoch)
- **Train Dice Score**: 0.898 (89.8%)
- **Train Loss**: 0.158

---

## ğŸ“ˆ í›ˆë ¨ ì§„í–‰ ìƒí™©

**ì´ í›ˆë ¨ ê¸°ê°„**: Epoch 0-49 (ì´ì „) + Epoch 50-99 (ì¬ê°œ)
- ì‹œì‘: Epoch 49, val_dice=0.9196
- ì¢…ë£Œ: Epoch 99, val_dice=0.9218
- ìµœê³ : Epoch 95, val_dice=0.9219

**ì„±ëŠ¥ ê°œì„ **:
- Resume ì‹œì‘ (Epoch 49): val_dice = 0.9196
- ìµœì¢… ìµœê³  ì„±ëŠ¥ (Epoch 95): val_dice = 0.9219
- **ê°œì„ ìœ¨**: +0.0023 (0.25% í–¥ìƒ)

---

## ğŸ’¾ ì €ì¥ëœ íŒŒì¼

### ì²´í¬í¬ì¸íŠ¸ (Top 3)
1. `models/unet_scratch/checkpoints/unet-epoch=95-val_dice=0.9219.ckpt` â­ (ìµœê³  ì„±ëŠ¥)
2. `models/unet_scratch/checkpoints/unet-epoch=98-val_dice=0.9218.ckpt`
3. `models/unet_scratch/checkpoints/unet-epoch=48-val_dice=0.9186.ckpt`
4. `models/unet_scratch/checkpoints/last.ckpt` (ë§ˆì§€ë§‰ epoch)

### ìµœì¢… ëª¨ë¸
- `models/unet_scratch/unet_best.pth` (í…ŒìŠ¤íŠ¸ ì™„ë£Œ ëª¨ë¸)

### ë¡œê·¸
- TensorBoard ë¡œê·¸: `models/unet_scratch/logs/unet_training/version_6/`

---

## ğŸ¯ ëª¨ë¸ ì‚¬ìš©ë²•

### 1. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ
```python
from src.segmentation.unet_lightning import UNetLightning

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
model = UNetLightning.load_from_checkpoint(
    'models/unet_scratch/checkpoints/unet-epoch=95-val_dice=0.9219.ckpt'
)
model.eval()
```

### 2. State Dictì—ì„œ ë¡œë“œ
```python
import torch

# ìµœì¢… ëª¨ë¸ ë¡œë“œ
model = UNetLightning(n_channels=1, n_classes=1)
model.load_state_dict(torch.load('models/unet_scratch/unet_best.pth'))
model.eval()
```

### 3. ì¶”ë¡  (Inference)
```python
import torch
from PIL import Image
import numpy as np

# ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
image = Image.open('path/to/image.png').convert('L')
image = np.array(image).astype(np.float32) / 255.0
image = torch.from_numpy(image).unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)

# ì¶”ë¡ 
with torch.no_grad():
    output = model(image)
    mask = (output > 0.5).float()  # Binary mask
```

---

## ğŸ” ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸

### ê°•ì 
1. âœ… **ë†’ì€ Dice Score**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ 91.42% ë‹¬ì„±
2. âœ… **ì•ˆì •ì ì¸ í›ˆë ¨**: Validationê³¼ Test ì„±ëŠ¥ ì°¨ì´ê°€ ì‘ìŒ (0.77%p)
3. âœ… **ì¼ê´€ëœ ê°œì„ **: Resume í›„ì—ë„ ê³„ì† ì„±ëŠ¥ í–¥ìƒ

### ê°œì„  ê°€ëŠ¥ ì˜ì—­
1. **Train-Val Gap**: Train dice(89.8%) vs Val dice(92.2%)
   - Validationì´ ë” ë†’ìŒ â†’ ë°ì´í„° ì¦ê°• íš¨ê³¼ ë˜ëŠ” ì‘ì€ validation set
2. **Val-Test Gap**: Val dice(92.2%) vs Test dice(91.4%)
   - ì•½ê°„ì˜ overfitting ê°€ëŠ¥ì„±

### ê¶Œì¥ì‚¬í•­
1. ë” ë§ì€ ë°ì´í„°ë¡œ í›ˆë ¨ ì‹œ ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒ
2. Test augmentation (TTA) ì ìš© ì‹œ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥
3. Ensemble ë°©ë²• ì ìš© ê³ ë ¤

---

## ğŸ“ í›ˆë ¨ ì„¤ì •

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
- Learning Rate: 1e-4
- Batch Size: 8
- Max Epochs: 100
- Optimizer: Adam (ê¸°ë³¸ ì„¤ì •)
- Loss: Combined Loss (BCE 50% + Dice 50%)

**ë°ì´í„° ë¶„í• **:
- Train: 140 samples (70%)
- Validation: 30 samples (15%)
- Test: 30 samples (15%)

**í•˜ë“œì›¨ì–´**:
- Device: CPU
- Training Speed: ~3-4ì´ˆ/epoch

---

## âœ… ë‹¤ìŒ ë‹¨ê³„

1. âœ… **í›ˆë ¨ ì™„ë£Œ** - U-Net ëª¨ë¸ ì¤€ë¹„ë¨
2. ğŸ”„ **ë‹¤ìŒ ì‘ì—…**:
   - USC-TIMIT ì „ì²´ ë°ì´í„°ì…‹ì— ì„¸ê·¸ë©˜í…Œì´ì…˜ ì ìš©
   - ì¶”ê°€ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í›ˆë ¨ (ì„ íƒì‚¬í•­)
   - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ taskì— ëª¨ë¸ í™œìš©

---

**ìƒì„± ì¼ì‹œ**: 2026-01-11
**ëª¨ë¸ ìƒíƒœ**: Production Ready âœ…
