# Transformer Full Training Configuration
# Production configuration for Phase 2-B

# Data settings
data:
  splits_dir: data/processed/splits
  audio_feature_dir: data/processed/audio_features
  parameter_dir: data/processed/parameters
  audio_feature_type: mel  # 'mel' or 'mfcc'
  parameter_type: geometric  # 'geometric' or 'pca'
  sequence_length: 100  # Split into 100-frame sequences (null = use full utterances)

# Model settings
model:
  name: Transformer
  input_dim: 80  # 80 for mel-spectrogram, 13 for MFCC
  d_model: 256  # Transformer hidden dimension
  num_layers: 4  # Number of transformer layers
  num_heads: 8  # Number of attention heads
  d_ff: 1024  # Feed-forward network dimension
  output_dim: 14  # 14 for geometric, 10 for PCA
  dropout: 0.1  # Dropout rate
  pos_encoding: learnable  # 'sinusoidal' or 'learnable'
  activation: gelu  # Activation function (gelu, relu, swish)
  learning_rate: 0.0005  # Initial learning rate
  weight_decay: 0.01  # Weight decay for AdamW
  max_seq_len: 5000  # Maximum sequence length

# Training settings
training:
  batch_size: 16  # Larger batch size for GPU (adjust based on VRAM)
  num_epochs: 50  # Full training epochs
  num_workers: 4  # Data loading workers (0 for CPU, 4+ for GPU)
  accumulate_grad_batches: 1  # Gradient accumulation (increase if OOM)
  gradient_clip_val: 1.0  # Gradient clipping
  precision: 16  # Mixed precision (16 for GPU, 32 for CPU)

# Optimization
optimization:
  optimizer: AdamW  # AdamW with decoupled weight decay
  learning_rate: 0.0005  # Learning rate
  weight_decay: 0.01  # Weight decay
  betas: [0.9, 0.98]  # Beta parameters for AdamW
  lr_scheduler: CosineAnnealingWarmRestarts  # Learning rate scheduler
  lr_scheduler_params:
    T_0: 10  # Restart every 10 epochs
    T_mult: 2  # Double period after each restart
    eta_min: 0.000001  # Minimum learning rate

# Callbacks
callbacks:
  early_stopping:
    monitor: val_loss
    patience: 15  # Patience for early stopping
    mode: min
    verbose: true
  model_checkpoint:
    monitor: val_loss
    mode: min
    save_top_k: 3  # Save top 3 checkpoints
    save_last: true  # Save last checkpoint
    filename: "transformer-{epoch:02d}-{val_loss:.4f}"

# Logging
logging:
  experiment_name: transformer_v1
  log_dir: logs/training
  save_dir: models/transformer
  log_every_n_steps: 10

# Evaluation
evaluation:
  metrics:
    - rmse
    - mae
    - pearson_correlation
  visualize_predictions: true
  num_samples_to_visualize: 5

# Reproducibility
seed: 42

# Hardware
device: cuda  # 'cpu' or 'cuda'
