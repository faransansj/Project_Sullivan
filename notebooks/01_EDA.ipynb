{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - USC Speech MRI Dataset\n",
    "\n",
    "**Project Sullivan - Milestone M1**\n",
    "\n",
    "**Date:** 2025-11-25\n",
    "\n",
    "**Researcher:** [Your Name]\n",
    "\n",
    "**Objective:** Understand the structure and characteristics of the USC-TIMIT Speech MRI dataset to inform preprocessing strategies for Phase 1.\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- [ ] Verify data download and extraction\n",
    "- [ ] Analyze MRI frame properties (resolution, fps, format)\n",
    "- [ ] Analyze audio properties (sample rate, duration, format)\n",
    "- [ ] Check audio-MRI synchronization\n",
    "- [ ] Visualize sample MRI frames and spectrograms\n",
    "- [ ] Identify data quality issues (noise, missing frames)\n",
    "- [ ] Document findings in `docs/data_statistics.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path('/home/midori/Develop/Project_Sullivan')\n",
    "DATA_RAW = PROJECT_ROOT / 'data' / 'raw'\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Directory: {DATA_RAW}\")\n",
    "print(f\"Python Version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all directories in data/raw\n",
    "print(\"Contents of data/raw:\")\n",
    "for item in DATA_RAW.iterdir():\n",
    "    if item.is_dir():\n",
    "        size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())\n",
    "        print(f\"  - {item.name}: {size / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find MRI files (update path based on actual data structure)\n",
    "mri_files = sorted(glob(str(DATA_RAW / '**' / '*.png'), recursive=True))\n",
    "mri_files += sorted(glob(str(DATA_RAW / '**' / '*.jpg'), recursive=True))\n",
    "mri_files += sorted(glob(str(DATA_RAW / '**' / '*.mp4'), recursive=True))\n",
    "\n",
    "print(f\"Total MRI-related files found: {len(mri_files)}\")\n",
    "if mri_files:\n",
    "    print(f\"\\nFirst 5 files:\")\n",
    "    for f in mri_files[:5]:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No MRI files found! Please download data from figshare.\")\n",
    "    print(\"See: docs/DATA_DOWNLOAD_GUIDE.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find audio files\n",
    "audio_files = sorted(glob(str(DATA_RAW / '**' / '*.wav'), recursive=True))\n",
    "audio_files += sorted(glob(str(DATA_RAW / '**' / '*.mp3'), recursive=True))\n",
    "\n",
    "print(f\"Total audio files found: {len(audio_files)}\")\n",
    "if audio_files:\n",
    "    print(f\"\\nFirst 5 files:\")\n",
    "    for f in audio_files[:5]:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No audio files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MRI Frame Analysis\n",
    "\n",
    "**Note:** This section assumes you have downloaded MRI frames. If not, skip to Section 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mri_files and mri_files[0].endswith('.png'):\n",
    "    # Load sample MRI frame\n",
    "    sample_mri_path = mri_files[0]\n",
    "    sample_mri = cv2.imread(sample_mri_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    print(f\"Sample MRI: {sample_mri_path}\")\n",
    "    print(f\"  Shape: {sample_mri.shape}\")\n",
    "    print(f\"  Dtype: {sample_mri.dtype}\")\n",
    "    print(f\"  Value range: [{sample_mri.min()}, {sample_mri.max()}]\")\n",
    "    print(f\"  Mean: {sample_mri.mean():.2f}\")\n",
    "    print(f\"  Std: {sample_mri.std():.2f}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axes[0].imshow(sample_mri, cmap='gray')\n",
    "    axes[0].set_title('Sample MRI Frame')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].hist(sample_mri.ravel(), bins=50, color='skyblue', edgecolor='black')\n",
    "    axes[1].set_title('Pixel Intensity Distribution')\n",
    "    axes[1].set_xlabel('Pixel Value')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PROJECT_ROOT / 'results' / 'eda_mri_sample.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Skipping MRI analysis - no PNG/JPG frames found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Audio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_files:\n",
    "    # Load sample audio\n",
    "    sample_audio_path = audio_files[0]\n",
    "    audio, sr = librosa.load(sample_audio_path, sr=None)\n",
    "    \n",
    "    print(f\"Sample Audio: {sample_audio_path}\")\n",
    "    print(f\"  Sample rate: {sr} Hz\")\n",
    "    print(f\"  Duration: {len(audio) / sr:.2f} seconds\")\n",
    "    print(f\"  Length: {len(audio)} samples\")\n",
    "    print(f\"  Value range: [{audio.min():.4f}, {audio.max():.4f}]\")\n",
    "    print(f\"  RMS: {np.sqrt(np.mean(audio**2)):.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ Skipping audio analysis - no audio files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_files:\n",
    "    # Visualize waveform and spectrogram\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Waveform\n",
    "    librosa.display.waveshow(audio, sr=sr, ax=axes[0])\n",
    "    axes[0].set_title('Audio Waveform')\n",
    "    axes[0].set_xlabel('Time (s)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "    axes[1].set_title('Spectrogram')\n",
    "    fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "    \n",
    "    # Mel Spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=80)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    img2 = librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel', ax=axes[2])\n",
    "    axes[2].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img2, ax=axes[2], format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PROJECT_ROOT / 'results' / 'eda_audio_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Audio-MRI Synchronization Check\n",
    "\n",
    "**Goal:** Verify that audio and MRI frames are temporally aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section requires knowing the correspondence between audio and MRI files\n",
    "# Update based on actual dataset structure\n",
    "\n",
    "# Example:\n",
    "# - MRI frame rate: 50 fps\n",
    "# - Audio sample rate: 20000 Hz\n",
    "# - Expected samples per frame: 20000 / 50 = 400 samples\n",
    "\n",
    "if mri_files and audio_files:\n",
    "    # Placeholder for synchronization analysis\n",
    "    print(\"⚠️ TODO: Implement synchronization check based on metadata\")\n",
    "    print(\"\\nExpected:\")\n",
    "    print(\"  - Frame timestamps from MRI metadata\")\n",
    "    print(\"  - Audio timestamps from sync signal or metadata\")\n",
    "    print(\"  - Cross-correlation for precise alignment\")\n",
    "else:\n",
    "    print(\"⚠️ Cannot check synchronization without both MRI and audio data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile statistics\n",
    "stats = {\n",
    "    'dataset': 'USC-TIMIT Speech MRI',\n",
    "    'data_downloaded': len(mri_files) > 0 or len(audio_files) > 0,\n",
    "    'mri_files_count': len(mri_files),\n",
    "    'audio_files_count': len(audio_files),\n",
    "}\n",
    "\n",
    "if mri_files and mri_files[0].endswith('.png'):\n",
    "    stats['mri_resolution'] = f\"{sample_mri.shape[1]}x{sample_mri.shape[0]}\"\n",
    "    stats['mri_dtype'] = str(sample_mri.dtype)\n",
    "    \n",
    "if audio_files:\n",
    "    stats['audio_sample_rate'] = sr\n",
    "    stats['audio_duration_sec'] = len(audio) / sr\n",
    "\n",
    "# Display\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET STATISTICS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:25s}: {value}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save to JSON\n",
    "stats_path = PROJECT_ROOT / 'docs' / 'data_statistics.json'\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "print(f\"\\nStatistics saved to: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps & Action Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If Data is NOT Downloaded:\n",
    "\n",
    "- [ ] **Download data from figshare** (see `docs/DATA_DOWNLOAD_GUIDE.md`)\n",
    "- [ ] Start with 1-2 subjects for testing\n",
    "- [ ] Re-run this notebook after download\n",
    "\n",
    "### If Data IS Downloaded:\n",
    "\n",
    "- [ ] **Document findings** in `docs/data_statistics.md`\n",
    "- [ ] **Identify preprocessing needs:**\n",
    "  - MRI noise reduction required?\n",
    "  - Audio filtering needed?\n",
    "  - Synchronization method?\n",
    "- [ ] **Proceed to Phase 1 - Step 2:** Denoising & Alignment\n",
    "- [ ] **Create preprocessing scripts** in `src/preprocessing/`\n",
    "\n",
    "### Research Log Entry\n",
    "\n",
    "- [ ] Update research log with EDA findings\n",
    "- [ ] Note any data quality issues\n",
    "- [ ] Plan next week's tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Experiment ID:** EXP-20251125-01-EDA\n",
    "\n",
    "**Status:** [In Progress / Completed]\n",
    "\n",
    "**Notes:** \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
