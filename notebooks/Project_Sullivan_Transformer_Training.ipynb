{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# Project Sullivan - Transformer Model Training\n\n**Phase 2-B: Advanced Architecture Training on Google Colab**\n\nThis notebook trains the Transformer model for acoustic-to-articulatory inversion.\n\n---\n\n## üìã Prerequisites\n\n**Nothing! Just run the notebook.**\n\nAll data (78MB) is included in the GitHub repository and will be automatically extracted.\n\n---\n\n## üöÄ Runtime Settings\n\n**IMPORTANT**: Change runtime to GPU\n- Menu: Runtime ‚Üí Change runtime type\n- Hardware accelerator: **GPU** (T4 recommended)\n- Click Save\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": "## ‚öôÔ∏è Configuration\n\nSimple configuration - just set your training mode:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_vars"
   },
   "outputs": [],
   "source": "# ============================================\n# Training Configuration\n# ============================================\nQUICK_TEST = False  # Set to True for 10-epoch validation test (20-30 min)\n                    # Set to False for full training (2-3 hours)\n\nCONFIG_FILE = 'configs/transformer_config.yaml' if not QUICK_TEST else 'configs/transformer_quick_test.yaml'\n\n# GitHub Repository (already set correctly)\nGITHUB_REPO = 'faransansj/Project_Sullivan'\nBRANCH = 'main'\n\n# ‚≠ê NOTE: sequence_length is now set in config files!\n# - transformer_config.yaml: sequence_length = 100\n# - This splits data into 100-frame sequences\n# - Train samples: 50 ‚Üí 1,240 (24x increase!)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not available! Training will be slow.\")\n",
    "    print(\"Please change runtime: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone GitHub repository\n",
    "import os\n",
    "\n",
    "if not os.path.exists('Project_Sullivan'):\n",
    "    !git clone https://github.com/{GITHUB_REPO}.git\n",
    "    %cd Project_Sullivan\n",
    "    !git checkout {BRANCH}\n",
    "else:\n",
    "    %cd Project_Sullivan\n",
    "    !git pull origin {BRANCH}\n",
    "\n",
    "print(\"\\n‚úÖ Repository ready!\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": "# Install dependencies\nprint(\"üì¶ Installing dependencies...\\n\")\n!pip install -q torch torchvision torchaudio\n!pip install -q pytorch-lightning tensorboard\n!pip install -q librosa soundfile\n!pip install -q numpy scipy matplotlib seaborn\n!pip install -q pyyaml tqdm\n\nprint(\"\\n‚úÖ Dependencies installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_data"
   },
   "source": "## üì• Extract Data from Repository"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_combined"
   },
   "outputs": [],
   "source": "# Extract data archives (already in repository)\nimport tarfile\nimport os\n\nprint(\"üì¶ Extracting data from repository archives...\\n\")\n\n# Create data directory\nos.makedirs('data/processed', exist_ok=True)\n\n# Extract combined archive\narchive_path = 'colab_data_archives/processed_data_all.tar.gz'\n\nif os.path.exists(archive_path):\n    print(f\"Found archive: {archive_path}\")\n    print(\"Extracting...\")\n    \n    with tarfile.open(archive_path, 'r:gz') as tar:\n        tar.extractall('data/processed')\n    \n    print(\"‚úÖ Data extracted!\\n\")\nelse:\n    print(\"‚ö†Ô∏è Archive not found. Trying individual archives...\\n\")\n    \n    # Try individual archives as fallback\n    archives = {\n        'audio_features': 'colab_data_archives/audio_features.tar.gz',\n        'parameters': 'colab_data_archives/parameters.tar.gz',\n        'segmentations': 'colab_data_archives/segmentations.tar.gz',\n        'splits': 'colab_data_archives/splits.tar.gz'\n    }\n    \n    for name, path in archives.items():\n        if os.path.exists(path):\n            print(f\"Extracting {name}...\")\n            with tarfile.open(path, 'r:gz') as tar:\n                tar.extractall('data/processed')\n    \n    print(\"\\n‚úÖ All data extracted!\")\n\n# Verify data\nprint(\"üìä Data verification:\")\n!ls -lh data/processed/"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üèãÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": "# Start training\nprint(f\"üöÄ Starting Transformer training ({CONFIG_FILE})...\\n\")\nprint(f\"Quick test mode: {QUICK_TEST}\")\nprint(f\"GPU available: {torch.cuda.is_available()}\\n\")\n\n# Run training script\n!python scripts/train_transformer.py \\\n    --config {CONFIG_FILE} \\\n    --gpus 1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tensorboard"
   },
   "source": [
    "## üìä Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## üìà View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "# Check training logs\n",
    "import glob\n",
    "\n",
    "log_dirs = glob.glob('logs/training/*/')\n",
    "if log_dirs:\n",
    "    latest_log = sorted(log_dirs)[-1]\n",
    "    print(f\"üìÅ Latest training run: {latest_log}\\n\")\n",
    "    \n",
    "    # Show metrics\n",
    "    metrics_file = os.path.join(latest_log, 'metrics.csv')\n",
    "    if os.path.exists(metrics_file):\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(metrics_file)\n",
    "        print(\"üìä Training Metrics:\")\n",
    "        print(df.tail(10))\n",
    "    \n",
    "    # List checkpoints\n",
    "    checkpoints = glob.glob(os.path.join(latest_log, 'checkpoints', '*.ckpt'))\n",
    "    if checkpoints:\n",
    "        print(f\"\\nüíæ Checkpoints ({len(checkpoints)} found):\")\n",
    "        for ckpt in sorted(checkpoints)[-3:]:\n",
    "            print(f\"   - {os.path.basename(ckpt)}\")\n",
    "else:\n",
    "    print(\"No training logs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_results"
   },
   "source": [
    "## üíæ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_results"
   },
   "outputs": [],
   "source": [
    "# Create archive of results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "archive_name = f'transformer_results_{timestamp}'\n",
    "\n",
    "# Copy important files\n",
    "os.makedirs(archive_name, exist_ok=True)\n",
    "\n",
    "# Copy logs\n",
    "if log_dirs:\n",
    "    shutil.copytree(latest_log, os.path.join(archive_name, 'logs'))\n",
    "\n",
    "# Create zip\n",
    "shutil.make_archive(archive_name, 'zip', archive_name)\n",
    "\n",
    "print(f\"\\nüì¶ Results archived: {archive_name}.zip\")\n",
    "print(f\"\\nüì• Download using Files panel (left sidebar)\")\n",
    "print(f\"   Or run: !cp {archive_name}.zip /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_to_drive"
   },
   "source": [
    "## üíæ Save to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy results to Drive\n",
    "drive_path = '/content/drive/MyDrive/Project_Sullivan_Results/'\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "!cp {archive_name}.zip {drive_path}\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to Google Drive: {drive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": "---\n\n## üìù Notes\n\n### Expected Training Time (T4 GPU)\n- Quick test (10 epochs): ~20-30 minutes\n- Full training (50 epochs): ~2-3 hours\n\n### Expected Performance\n- **Target RMSE**: 0.20-0.30 (3-5√ó better than baseline LSTM)\n- **Target PCC**: 0.30-0.45 (3-4√ó better than baseline LSTM)\n- **Baseline LSTM**: RMSE 1.011, PCC 0.105\n\n### Advantages of This Setup\n- **No Google Drive needed** - all data in repository\n- **No manual configuration** - just set QUICK_TEST and run\n- **Automatic extraction** - data extracted from included archives\n- **Simple and fast** - fewer steps, less setup time\n\n### Troubleshooting\n\n**Out of Memory Error:**\n- Reduce batch size in config file\n- Use gradient accumulation\n\n**GPU not available:**\n- Runtime ‚Üí Change runtime type ‚Üí GPU\n- May need to wait for GPU allocation\n\n**Data extraction fails:**\n- Check that repository cloned successfully\n- Verify `colab_data_archives/` folder exists\n\n---\n\n**Updated**: 2025-12-02  \n**Project**: Sullivan - Acoustic-to-Articulatory Inversion  \n**Phase**: 2-B Transformer Training  \n**Setup**: Simplified - No Google Drive required!"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}