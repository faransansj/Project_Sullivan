{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Project Sullivan - Transformer Model Training\n",
    "\n",
    "**Phase 2-B: Advanced Architecture Training on Google Colab**\n",
    "\n",
    "This notebook trains the Transformer model for acoustic-to-articulatory inversion.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "1. Upload compressed data to Google Drive:\n",
    "   - `processed_data_all.tar.gz` (78MB) - Recommended (all data in one file)\n",
    "   - OR individual files:\n",
    "     - `audio_features.tar.gz` (48MB)\n",
    "     - `parameters.tar.gz` (11MB)\n",
    "     - `segmentations.tar.gz` (19MB)\n",
    "     - `splits.tar.gz` (4KB)\n",
    "\n",
    "2. Get shareable links (Anyone with link can view)\n",
    "\n",
    "3. Extract file IDs from URLs:\n",
    "   - URL format: `https://drive.google.com/file/d/FILE_ID/view`\n",
    "   - Copy the `FILE_ID` part\n",
    "\n",
    "4. Update the `GDRIVE_FILE_ID` variable below\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Runtime Settings\n",
    "\n",
    "**IMPORTANT**: Change runtime to GPU\n",
    "- Menu: Runtime ‚Üí Change runtime type\n",
    "- Hardware accelerator: **GPU** (T4 recommended)\n",
    "- Click Save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Update these variables with your Google Drive file IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_vars"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Google Drive File IDs\n",
    "# ============================================\n",
    "# Replace 'YOUR_FILE_ID_HERE' with actual file ID from Google Drive\n",
    "\n",
    "# Option 1: Use combined archive (recommended)\n",
    "GDRIVE_FILE_ID_ALL = 'YOUR_FILE_ID_HERE'  # processed_data_all.tar.gz\n",
    "USE_COMBINED_ARCHIVE = True\n",
    "\n",
    "# Option 2: Use individual archives (if combined fails)\n",
    "GDRIVE_FILE_IDS = {\n",
    "    'audio_features': 'YOUR_FILE_ID_HERE',\n",
    "    'parameters': 'YOUR_FILE_ID_HERE',\n",
    "    'segmentations': 'YOUR_FILE_ID_HERE',\n",
    "    'splits': 'YOUR_FILE_ID_HERE'\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# Training Configuration\n",
    "# ============================================\n",
    "QUICK_TEST = False  # Set to True for 10-epoch validation test\n",
    "CONFIG_FILE = 'configs/transformer_config.yaml' if not QUICK_TEST else 'configs/transformer_quick_test.yaml'\n",
    "\n",
    "# GitHub Repository\n",
    "GITHUB_REPO = 'YOUR_GITHUB_USERNAME/Project_Sullivan'  # Update with your repo\n",
    "BRANCH = 'main'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not available! Training will be slow.\")\n",
    "    print(\"Please change runtime: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone GitHub repository\n",
    "import os\n",
    "\n",
    "if not os.path.exists('Project_Sullivan'):\n",
    "    !git clone https://github.com/{GITHUB_REPO}.git\n",
    "    %cd Project_Sullivan\n",
    "    !git checkout {BRANCH}\n",
    "else:\n",
    "    %cd Project_Sullivan\n",
    "    !git pull origin {BRANCH}\n",
    "\n",
    "print(\"\\n‚úÖ Repository ready!\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q pytorch-lightning tensorboard\n",
    "!pip install -q librosa soundfile\n",
    "!pip install -q numpy scipy matplotlib seaborn\n",
    "!pip install -q pyyaml tqdm\n",
    "!pip install -q gdown  # For Google Drive downloads\n",
    "\n",
    "print(\"\\n‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_data"
   },
   "source": [
    "## üì• Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_combined"
   },
   "outputs": [],
   "source": [
    "# Download and extract data\n",
    "import gdown\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "if USE_COMBINED_ARCHIVE:\n",
    "    print(\"üì• Downloading combined data archive...\\n\")\n",
    "    \n",
    "    # Download\n",
    "    url = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID_ALL}'\n",
    "    output = 'processed_data_all.tar.gz'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "    \n",
    "    # Extract\n",
    "    print(\"\\nüì¶ Extracting archive...\")\n",
    "    with tarfile.open(output, 'r:gz') as tar:\n",
    "        tar.extractall('data/processed')\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(output)\n",
    "    print(\"‚úÖ Data extracted!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üì• Downloading individual archives...\\n\")\n",
    "    \n",
    "    for name, file_id in GDRIVE_FILE_IDS.items():\n",
    "        print(f\"\\nDownloading {name}...\")\n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        output = f'{name}.tar.gz'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        \n",
    "        # Extract\n",
    "        print(f\"Extracting {name}...\")\n",
    "        with tarfile.open(output, 'r:gz') as tar:\n",
    "            tar.extractall('data/processed')\n",
    "        \n",
    "        # Cleanup\n",
    "        os.remove(output)\n",
    "    \n",
    "    print(\"\\n‚úÖ All data extracted!\")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nüìä Data verification:\")\n",
    "!ls -lh data/processed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üèãÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(f\"üöÄ Starting Transformer training ({CONFIG_FILE})...\\n\")\n",
    "print(f\"Quick test mode: {QUICK_TEST}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\\n\")\n",
    "\n",
    "# Run training script\n",
    "!python scripts/train_transformer.py \\\n",
    "    --config {CONFIG_FILE} \\\n",
    "    --gpus 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tensorboard"
   },
   "source": [
    "## üìä Monitor Training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## üìà View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "# Check training logs\n",
    "import glob\n",
    "\n",
    "log_dirs = glob.glob('logs/training/*/')\n",
    "if log_dirs:\n",
    "    latest_log = sorted(log_dirs)[-1]\n",
    "    print(f\"üìÅ Latest training run: {latest_log}\\n\")\n",
    "    \n",
    "    # Show metrics\n",
    "    metrics_file = os.path.join(latest_log, 'metrics.csv')\n",
    "    if os.path.exists(metrics_file):\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(metrics_file)\n",
    "        print(\"üìä Training Metrics:\")\n",
    "        print(df.tail(10))\n",
    "    \n",
    "    # List checkpoints\n",
    "    checkpoints = glob.glob(os.path.join(latest_log, 'checkpoints', '*.ckpt'))\n",
    "    if checkpoints:\n",
    "        print(f\"\\nüíæ Checkpoints ({len(checkpoints)} found):\")\n",
    "        for ckpt in sorted(checkpoints)[-3:]:\n",
    "            print(f\"   - {os.path.basename(ckpt)}\")\n",
    "else:\n",
    "    print(\"No training logs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_results"
   },
   "source": [
    "## üíæ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_results"
   },
   "outputs": [],
   "source": [
    "# Create archive of results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "archive_name = f'transformer_results_{timestamp}'\n",
    "\n",
    "# Copy important files\n",
    "os.makedirs(archive_name, exist_ok=True)\n",
    "\n",
    "# Copy logs\n",
    "if log_dirs:\n",
    "    shutil.copytree(latest_log, os.path.join(archive_name, 'logs'))\n",
    "\n",
    "# Create zip\n",
    "shutil.make_archive(archive_name, 'zip', archive_name)\n",
    "\n",
    "print(f\"\\nüì¶ Results archived: {archive_name}.zip\")\n",
    "print(f\"\\nüì• Download using Files panel (left sidebar)\")\n",
    "print(f\"   Or run: !cp {archive_name}.zip /content/drive/MyDrive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_to_drive"
   },
   "source": [
    "## üíæ Save to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy results to Drive\n",
    "drive_path = '/content/drive/MyDrive/Project_Sullivan_Results/'\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "!cp {archive_name}.zip {drive_path}\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to Google Drive: {drive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "### Expected Training Time (T4 GPU)\n",
    "- Quick test (10 epochs): ~20-30 minutes\n",
    "- Full training (50 epochs): ~2-3 hours\n",
    "\n",
    "### Expected Performance\n",
    "- **Target RMSE**: 0.20-0.30 (3-5√ó better than baseline LSTM)\n",
    "- **Target PCC**: 0.30-0.45 (3-4√ó better than baseline LSTM)\n",
    "- **Baseline LSTM**: RMSE 1.011, PCC 0.105\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Out of Memory Error:**\n",
    "- Reduce batch size in config file\n",
    "- Use gradient accumulation\n",
    "\n",
    "**GPU not available:**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- May need to wait for GPU allocation\n",
    "\n",
    "**Download fails:**\n",
    "- Check file IDs are correct\n",
    "- Ensure sharing is set to \"Anyone with link\"\n",
    "- Try individual archives instead of combined\n",
    "\n",
    "---\n",
    "\n",
    "**Generated**: 2025-12-01  \n",
    "**Project**: Sullivan - Acoustic-to-Articulatory Inversion  \n",
    "**Phase**: 2-B Transformer Training\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
